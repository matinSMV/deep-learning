{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BenyaminZojaji/Deep_Learning/blob/main/sheikhDetector/sheikhDetector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0o3X28tbWM1"
      },
      "outputs": [],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mvonXP4cfXy"
      },
      "source": [
        "### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "Y1LPIPzebeXL"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "import cv2\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6Dzw75PcipI"
      },
      "source": [
        "### Wandb configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "CNu_w7hqcqBl",
        "outputId": "c6b8bc41-fd93-423b-fa65-1123a0a9c544"
      },
      "outputs": [],
      "source": [
        "wandb.init(project=\"sheykh-detection\", entity=\"matin-samvatian\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "o1HCH7o_cmxN"
      },
      "outputs": [],
      "source": [
        "config = wandb.config\n",
        "config.learning_rate = 0.001"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJYs3n1Bcs_p"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRQulKyxcu-s",
        "outputId": "c3aeba78-bd43-45bb-d777-a9dc8fd4fbc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 212 images belonging to 2 classes.\n",
            "Found 52 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_dataset_path = '/content/drive/MyDrive/sheykh-dataset'\n",
        "width = height = 224\n",
        "batch_size = 32\n",
        "\n",
        "idg = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "\n",
        "    # Augmentation\n",
        "    horizontal_flip = True,\n",
        "    zoom_range = 0.1,\n",
        "    rotation_range = 10,\n",
        "    brightness_range = (0.8, 1.2),\n",
        "    validation_split = 0.2\n",
        ")\n",
        "\n",
        "train_data = idg.flow_from_directory(\n",
        "    train_dataset_path,\n",
        "    target_size=(width, height),\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size,\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_data = idg.flow_from_directory(\n",
        "    train_dataset_path,\n",
        "    target_size=(width, height),\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size,\n",
        "    subset='validation'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpPRS1ZH4P7V"
      },
      "source": [
        "### Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "o-bxN5Fthgrg",
        "outputId": "edfec93e-b489-4bde-8ca9-a7117af31bab"
      },
      "outputs": [],
      "source": [
        "some_images = next(train_data)\n",
        "X=some_images[0]\n",
        "Y=some_images[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySx6lYHm4Nw3"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "JdNFrWTujJig"
      },
      "outputs": [],
      "source": [
        "base_model = tf.keras.applications.VGG16(\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=(width,height,3),\n",
        "    include_top=False,\n",
        "    pooling='avg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "3nVvVOlG-mMh"
      },
      "outputs": [],
      "source": [
        "base_model.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "ly0K_0hSkY21"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    base_model,\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(2, activation=\"softmax\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JE7bfObJkO8W"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "POYjcm2Mj_bY"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.categorical_crossentropy,\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3qLKv2LkI3M",
        "outputId": "6908ad20-30d1-439e-a79f-007f4e6fef4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "7/7 [==============================] - 13s 2s/step - loss: 0.7565 - accuracy: 0.4858 - val_loss: 0.6799 - val_accuracy: 0.5000 - _timestamp: 1647423005.0000 - _runtime: 74.0000\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 12s 2s/step - loss: 0.6654 - accuracy: 0.6038 - val_loss: 0.6152 - val_accuracy: 0.8269 - _timestamp: 1647423017.0000 - _runtime: 86.0000\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 11s 1s/step - loss: 0.6001 - accuracy: 0.7736 - val_loss: 0.5263 - val_accuracy: 0.9231 - _timestamp: 1647423036.0000 - _runtime: 105.0000\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 11s 2s/step - loss: 0.4913 - accuracy: 0.8868 - val_loss: 0.4042 - val_accuracy: 0.9231 - _timestamp: 1647423048.0000 - _runtime: 117.0000\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 11s 2s/step - loss: 0.3805 - accuracy: 0.9009 - val_loss: 0.2762 - val_accuracy: 0.9423 - _timestamp: 1647423058.0000 - _runtime: 127.0000\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 11s 2s/step - loss: 0.2974 - accuracy: 0.8821 - val_loss: 0.2104 - val_accuracy: 0.9231 - _timestamp: 1647423069.0000 - _runtime: 138.0000\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 10s 1s/step - loss: 0.2142 - accuracy: 0.9104 - val_loss: 0.2315 - val_accuracy: 0.9423 - _timestamp: 1647423080.0000 - _runtime: 149.0000\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 11s 2s/step - loss: 0.1893 - accuracy: 0.9198 - val_loss: 0.1643 - val_accuracy: 0.9615 - _timestamp: 1647423090.0000 - _runtime: 159.0000\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 11s 1s/step - loss: 0.1648 - accuracy: 0.9340 - val_loss: 0.1490 - val_accuracy: 0.9615 - _timestamp: 1647423101.0000 - _runtime: 170.0000\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 11s 1s/step - loss: 0.1681 - accuracy: 0.9245 - val_loss: 0.1933 - val_accuracy: 0.9615 - _timestamp: 1647423113.0000 - _runtime: 182.0000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2fb5eec590>"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(train_data, validation_data=val_data, epochs=10, callbacks=[WandbCallback()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "QGX5R6j8mIpV"
      },
      "outputs": [],
      "source": [
        "model.save('sheykh-detection.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iR6z9Wvl83c",
        "outputId": "2847433e-f820-4012-c438-969eedb2aa7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 24 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "test_dataset_path = '/content/drive/MyDrive/Sheykh-test'\n",
        "width = height = 224\n",
        "batch_size = 32\n",
        "\n",
        "idg = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        ")\n",
        "\n",
        "test_data = idg.flow_from_directory(\n",
        "    test_dataset_path,\n",
        "    target_size=(width, height),\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzDZ-4r8JpUH",
        "outputId": "2862d215-3b37-4388-aad9-eb425199b2b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 866ms/step - loss: 0.2865 - accuracy: 0.9583\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.28649869561195374, 0.9583333134651184]"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "266QPNZVwDrt"
      },
      "outputs": [],
      "source": [
        "Y_pred = []\n",
        "\n",
        "for path in test_data.filepaths:\n",
        "  try:\n",
        "    img = cv2.imread(path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, (width, height))\n",
        "    img = img / 255\n",
        "    img = img.reshape(1, width, height, 3)\n",
        "    Y_pred.append(np.argmax(model.predict(img)))\n",
        "  except:\n",
        "    print(path)#if image isn't readable\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "vU-swfX1wMvp",
        "outputId": "aaf177dc-3924-43a3-8680-6bc211e96209"
      },
      "outputs": [],
      "source": [
        "# conf_mat = confusion_matrix(test_data.classes, Y_pred)\n",
        "# sn.set(font_scale=1.4) \n",
        "# sn.heatmap(conf_mat, annot=True, annot_kws={\"size\": 16})\n",
        "# plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMuaOR5/eCOXj1bX7IV3CHH",
      "collapsed_sections": [
        "lpPRS1ZH4P7V"
      ],
      "include_colab_link": true,
      "mount_file_id": "1OgvTXH-mzG2FB_mO-drnhRaXab-7mVfr",
      "name": "sheykhDetector.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
